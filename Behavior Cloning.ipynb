{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation and Formatting\n",
    "Flip images and measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 120\n",
    "IMAGE_HEIGHT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lines = []\n",
    "with open(\"./data/driving_log.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        filename = line[0].split('/')\n",
    "        try:\n",
    "            old_filename = '/'.join(['data',filename[-2],filename[-1]])\n",
    "            new_filename = '/'.join(['data_cleaned',filename[-2],filename[-1]])\n",
    "            img = cv2.imread(old_filename, cv2.IMREAD_COLOR)\n",
    "            img = img[55:-30, :] #crop\n",
    "            img = cv2.resize(img, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv2.INTER_CUBIC) #resize\n",
    "            cv2.imwrite(new_filename, img)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(old_filename, \"::\", new_filename)\n",
    "        lines.append([new_filename, line[-4]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21733\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))\n",
    "fw = open(\"./data_cleaned/driving_log.csv\", \"w\")\n",
    "for line in lines:\n",
    "    fw.write(\"{},{}\\n\".format(*line))\n",
    "    #if  abs(float(line[1])) > 0.15:\n",
    "    new_filename = line[0][:-4]+\"_flipped.jpg\"\n",
    "    img = cv2.imread(line[0], cv2.IMREAD_COLOR)\n",
    "    img = np.fliplr(img)\n",
    "    fw.write(\"{},{}\\n\".format(new_filename, -1.0 * float(line[1])))\n",
    "    cv2.imwrite(new_filename, img)\n",
    "    \n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "TRAIN_SPLIT_RATIO = 0.6\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "VALIDATION_SPLIT_RATIO = 0.2\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"./data_cleaned/driving_log.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        data.append(line)\n",
    "        \n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "TRAIN_END = int(len(data)*TRAIN_SPLIT_RATIO)\n",
    "VAL_END = TRAIN_END + int(len(data)*VALIDATION_SPLIT_RATIO)\n",
    "\n",
    "train_data = data[:TRAIN_END]\n",
    "validation_data = data[TRAIN_END:VAL_END]\n",
    "test_data = data[VAL_END:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26079, 0.5999861961073023)\n",
      "(8694, 0.20001840519026365)\n",
      "(8693, 0.19999539870243407)\n"
     ]
    }
   ],
   "source": [
    "total = 1.0* len(train_data)+len(test_data)+len(validation_data)\n",
    "print(len(train_data), len(train_data)/total )\n",
    "print(len(test_data), len(test_data)/total)\n",
    "print(len(validation_data), len(validation_data)/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    samples = np.array(samples)\n",
    "    np.random.shuffle(samples)\n",
    "    print(samples[0])\n",
    "    offset = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "                    \n",
    "        if offset >= num_samples:\n",
    "            offset = 0\n",
    "        vals = np.zeros((batch_size, 1))\n",
    "        imgs = np.zeros((batch_size, IMAGE_HEIGHT,IMAGE_WIDTH, 3))\n",
    "        index = 0\n",
    "        while index < batch_size:\n",
    "            batch_sample = samples[offset]\n",
    "            offset += 1\n",
    "            if offset >= num_samples:\n",
    "                offset = 0\n",
    "            filename = batch_sample[0]\n",
    "            center_image = cv2.imread(filename)\n",
    "            imgs[index] = center_image\n",
    "            vals[index][0] = float(batch_sample[1]) #steering angle\n",
    "            index += 1\n",
    "\n",
    "        X_train = imgs\n",
    "        y_train = vals\n",
    "            \n",
    "        yield X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "validation_data_size = len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_data, batch_size=batch_size)\n",
    "validation_generator = generator(validation_data, batch_size=batch_size)\n",
    "test_generator = generator(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras.models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e95b8abe73e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCropping2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras.models"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Lambda, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "import keras.regularizers as regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def nVidiaModel():\n",
    "    \"\"\"\n",
    "    Creates nVidea Autonomous Car Group model\n",
    "    \"\"\"\n",
    "    model = createPreProcessingLayers()\n",
    "    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d620de5940a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.add(Cropping2D(cropping=((10,2),(0,0)), input_shape=(32, 32, 3)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m127.5\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMAGE_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Cropping2D(cropping=((10,2),(0,0)), input_shape=(32, 32, 3)))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH, 3)))\n",
    "model.add(Conv2D(64, (5,5)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(64, (5,5)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(32, (3,3), strides=(2, 2)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(32, (3,3), strides=(2, 2)))\n",
    "model.add(ELU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(ELU())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "model.add(Dense(64))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Lambda, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Cropping2D(cropping=((10,2),(0,0)), input_shape=(32, 32, 3)))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0, input_shape=(40,80, 3)))\n",
    "model.add(Conv2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "model.add(ELU())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(lr=.0001), loss='mse', metrics=[ 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "checkpoint_callback = ModelCheckpoint('model{epoch:02d}.h5')\n",
    "history = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=train_data_size/batch_size, \\\n",
    "                   validation_data=validation_generator, validation_steps=validation_data_size/batch_size, \\\n",
    "                    max_q_size=2, callbacks=[checkpoint_callback], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(test_generator, val_samples=test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in zip(model.metrics_names, metrics):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"n_model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"model22.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
